from torchvision import transforms
a = transforms.PILToTensor()
t = a(image)
t
>>> tensor로 변경. 정규환 안시키고 그대로 나옴

b = transforms.ToPILImage()
b(t)
>>> 다시 이미지로 변경

--------------------------

transforms.PILToTensor()
이거 사용해도 torch.Tensor가 아니라 torch.Size로 numpy.array형식이 그대로 유지되는 것 같음..

그냥 transforms.ToTensor()를 사용해서 torch.tensor로 변경하고 각 원소에 255를 곱해주는 방식으로 해결

PTLToTensor()는 왜 있는지 궁금하다. 일단 패스

--------------------------
out_features는 또 그냥 torch.Tensor면 안됨
torch.LongTensor가 들어가야 정상 작동함. 일단 클래스 데이터에 한해서는 이런데 다른 모양은 데이터는 아직 모르겠다...

-----------------------------
2022-02-25
0. github 내 branch를 master로 merge해보기.(팀원들한테 말하고)->ok
1. 데이터를 사람별로 계통추출하는 인덱스를 만들고 train data, test data를 클래스로 나눠담기->ok
2. 베이스라인에서 submission.csv 만드는 코드 내 코드에 붙이기
3. submission.csv만들어서 업로드 해보기
4. special mission을 다시 따라해보기
5. 원본 이미지 검토하기
6. 기존 모델 가져다 쓰는 방법 배우기
7. 트레이닝 데이터 저장 및 불러오는 방법 배우기
8. 덴스레이어 나눠서 학습시키는 방법 배우기

-----------------------------------------

제목 : 이미지 데이터를 왜 정규화 해야하나요?

서론



# 이미지를 정규화하지 않고 기존 숫자로 사용한 결과
epoch:[0] loss:[3.293] train_accr:[0.145] test_accr:[0.146].
epoch:[1] loss:[2.327] train_accr:[0.145] test_accr:[0.146].
epoch:[2] loss:[2.402] train_accr:[0.145] test_accr:[0.146].
epoch:[3] loss:[2.321] train_accr:[0.145] test_accr:[0.146].

왜 학습이 안되는 걸까?
 - 스케일링(정규화)를 안해서
스케일링을 하면 왜 학습이 잘 되나?
 - 머신러닝 알고리즘은 숫자 자체만 보는데 속성이 다른 숫자들의 차이가 


# 동일한 모델을 정규화만 시켰을 때 학습결과
epoch:[0] loss:[3.809] train_accr:[0.408] test_accr:[0.393].
epoch:[1] loss:[1.931] train_accr:[0.536] test_accr:[0.503].
epoch:[2] loss:[1.656] train_accr:[0.617] test_accr:[0.558].
epoch:[3] loss:[1.416] train_accr:[0.670] test_accr:[0.591].
epoch:[4] loss:[1.199] train_accr:[0.722] test_accr:[0.612].
epoch:[5] loss:[1.020] train_accr:[0.795] test_accr:[0.654].
epoch:[6] loss:[0.876] train_accr:[0.839] test_accr:[0.670].
epoch:[7] loss:[0.742] train_accr:[0.860] test_accr:[0.665].
epoch:[8] loss:[0.631] train_accr:[0.926] test_accr:[0.693].
epoch:[9] loss:[0.542] train_accr:[0.934] test_accr:[0.677].

결론
이론적으로 정규화를 시키지 않은 모델도 학습을 시킬 수 있지만
lreaning rate를 찾기 힘들 뿐만아니라 시간도 오래걸려 비효율적이다.
이런 문제들을 scaling이 해결해준다.
다만 모든 문제를 해결해주는 만능키는 아니다.

사족
이제 망설임 없이 transforms.ToTensor를 사용하겠다.
하지만 다양한 스케일링 방법이 있다는 걸 염두해두자.

참조
https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35


-----------------------------

원본 데이터 검수 중 발견한 특징 중 incorrect mask와 mask2 이미지의 마스크 색이 항상 같은 걸 발견
경륜님 EDA에서 이미지를 텐서로 변경한 후 line plot으로 마스크 착용여부를 비교한 정보가 있는데 거기서도 감지가 됐었던 것 같은데 확인을 해봐야함

그래서 색깔 때문에 학습에 혼란을 줄 수 있겠다고 판단해서 그레이 스케일링을 적용

epoch:[0] loss:[3.998] train_accr:[0.381] test_accr:[0.372].
epoch:[1] loss:[2.183] train_accr:[0.457] test_accr:[0.435].
epoch:[2] loss:[1.916] train_accr:[0.502] test_accr:[0.461].
epoch:[3] loss:[1.722] train_accr:[0.540] test_accr:[0.483].
epoch:[4] loss:[1.575] train_accr:[0.581] test_accr:[0.494].
epoch:[5] loss:[1.413] train_accr:[0.632] test_accr:[0.508].
epoch:[6] loss:[1.276] train_accr:[0.701] test_accr:[0.539].
epoch:[7] loss:[1.115] train_accr:[0.757] test_accr:[0.526].
epoch:[8] loss:[0.965] train_accr:[0.853] test_accr:[0.563].
epoch:[9] loss:[0.811] train_accr:[0.869] test_accr:[0.572].
epoch:[10] loss:[0.714] train_accr:[0.926] test_accr:[0.582].
epoch:[11] loss:[0.609] train_accr:[0.955] test_accr:[0.569].
epoch:[12] loss:[0.548] train_accr:[0.962] test_accr:[0.568].
epoch:[13] loss:[0.482] train_accr:[0.979] test_accr:[0.587].
epoch:[14] loss:[0.440] train_accr:[0.985] test_accr:[0.581].
epoch:[15] loss:[0.396] train_accr:[0.985] test_accr:[0.595].
epoch:[16] loss:[0.348] train_accr:[0.991] test_accr:[0.588].
epoch:[17] loss:[0.331] train_accr:[0.994] test_accr:[0.592].
epoch:[18] loss:[0.303] train_accr:[0.992] test_accr:[0.583].
epoch:[19] loss:[0.290] train_accr:[0.994] test_accr:[0.589].

결과는 적용 전보다 나쁘다.
왜 그럴까?

이미지를 다 확인해보니 incorrect mask가 하늘색 마스크만 있는게 아니었음. 그레이 스케일링 취소!